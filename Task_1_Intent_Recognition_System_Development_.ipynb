{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeQpXQblxMdjpQCZ1fzgHV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arizzaa13/Intent-Recognition-System-Development-/blob/main/Task_1_Intent_Recognition_System_Development_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyWDUGG1KJBc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/Intent.json', 'r') as f:\n",
        "\tdata = json.load(f)\n",
        "\n",
        "print(data.keys())\n",
        "print(type(data['intents']))\n",
        "print(len(data['intents']))\n",
        "print(data['intents'][0].keys())\n",
        "data['intents'][-1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovXR5JyzK1fn",
        "outputId": "f7979b85-87e0-4734-f1a5-efb9563b6371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['intents'])\n",
            "<class 'list'>\n",
            "22\n",
            "dict_keys(['intent', 'text', 'responses', 'extension', 'context', 'entityType', 'entities'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 'SelfAware',\n",
              " 'text': ['Can you prove you are self-aware',\n",
              "  'Can you prove you are self aware',\n",
              "  'Can you prove you have a conscious',\n",
              "  'Can you prove you are self-aware please',\n",
              "  'Can you prove you are self aware please',\n",
              "  'Can you prove you have a conscious please',\n",
              "  'prove you have a conscious'],\n",
              " 'responses': ['That is an interesting question, can you prove that you are?',\n",
              "  'That is an difficult question, can you prove that you are?',\n",
              "  'That depends, can you prove that you are?'],\n",
              " 'extension': {'function': '', 'entities': False, 'responses': []},\n",
              " 'context': {'in': '', 'out': '', 'clear': False},\n",
              " 'entityType': 'NA',\n",
              " 'entities': []}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(line):\n",
        "\tcleaned_line = ''\n",
        "\tfor char in line:\n",
        "\t\tif char.isalpha():\n",
        "\t\t\tcleaned_line += char\n",
        "\t\telse:\n",
        "\t\t\tcleaned_line += ' '\n",
        "\tcleaned_line = ' '.join(cleaned_line.split())\n",
        "\treturn cleaned_line\n"
      ],
      "metadata": {
        "id": "FRK5bGsPLtoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list of intents\n",
        "intents = []\n",
        "unique_intents = []\n",
        "#all text data to create a corpus\n",
        "text_input= []\n",
        "#dictionary mapping intent with appropriate response\n",
        "response_for_intent = {}\n",
        "for intent in data['intents']:\n",
        "\t#list of unique intents\n",
        "\tif intent['intent'] not in unique_intents:\n",
        "\t\tunique_intents.append(intent['intent'])\n",
        "\tfor text in intent['text']:\n",
        "\t\t#cleaning is done before adding text to corpus\n",
        "\t\ttext_input.append(clean(text))\n",
        "\t\tintents.append(intent['intent'])\n",
        "\tif intent['intent'] not in response_for_intent:\n",
        "\t\tresponse_for_intent[intent['intent']] = []\n",
        "\tfor response in intent['responses']:\n",
        "\t\tresponse_for_intent[intent['intent']].append(response)\n"
      ],
      "metadata": {
        "id": "qN3ZZMvjL0VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Intent :\",intents[0])\n",
        "print(\"Number of Intent:\",len(intents))\n",
        "print(\"Sample Input:\", text_input[0])\n",
        "print('Length of text_input:',len(text_input))\n",
        "print(\"Sample Response: \", response_for_intent[intents[0]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWXmyWqPL5zZ",
        "outputId": "f5728849-42d6-477b-d22f-119d2a64ff92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent : Greeting\n",
            "Number of Intent: 143\n",
            "Sample Input: Hi\n",
            "Length of text_input: 143\n",
            "Sample Response:  ['Hi human, please tell me your GeniSys user', 'Hello human, please tell me your GeniSys user', 'Hola human, please tell me your GeniSys user']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(filters='',oov_token='<unk>')\n",
        "tokenizer.fit_on_texts(text_input)\n",
        "sequences = tokenizer.texts_to_sequences(text_input)\n",
        "padded_sequences = pad_sequences(sequences, padding='pre')\n",
        "print('Shape of Input Sequence:',padded_sequences.shape)\n",
        "padded_sequences[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8z3VkLBMAL7",
        "outputId": "332f050b-4850-40d3-c791-8251ba30f462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Input Sequence: (143, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0, 52],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 52, 53],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 68],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 39],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 39, 53]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intent_to_index = {}\n",
        "categorical_target = []\n",
        "index = 0\n",
        "\n",
        "for intent in intents:\n",
        "\tif intent not in intent_to_index:\n",
        "\t\tintent_to_index[intent] = index\n",
        "\t\tindex += 1\n",
        "\tcategorical_target.append(intent_to_index[intent])\n",
        "\n",
        "num_classes = len(intent_to_index)\n",
        "print('Number of Intents :',num_classes)\n",
        "\n",
        "# Convert intent_to_index to index_to_intent\n",
        "index_to_intent = {index: intent for intent, index in intent_to_index.items()}\n",
        "index_to_intent\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzEXh_eFMFKt",
        "outputId": "dd32699b-ef4a-4a46-bed2-e94302936f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Intents : 22\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Greeting',\n",
              " 1: 'GreetingResponse',\n",
              " 2: 'CourtesyGreeting',\n",
              " 3: 'CourtesyGreetingResponse',\n",
              " 4: 'CurrentHumanQuery',\n",
              " 5: 'NameQuery',\n",
              " 6: 'RealNameQuery',\n",
              " 7: 'TimeQuery',\n",
              " 8: 'Thanks',\n",
              " 9: 'NotTalking2U',\n",
              " 10: 'UnderstandQuery',\n",
              " 11: 'Shutup',\n",
              " 12: 'Swearing',\n",
              " 13: 'GoodBye',\n",
              " 14: 'CourtesyGoodBye',\n",
              " 15: 'WhoAmI',\n",
              " 16: 'Clever',\n",
              " 17: 'Gossip',\n",
              " 18: 'Jokes',\n",
              " 19: 'PodBayDoor',\n",
              " 20: 'PodBayDoorResponse',\n",
              " 21: 'SelfAware'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_vec = tf.keras.utils.to_categorical(categorical_target,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tnum_classes=num_classes, dtype='int32')\n",
        "\n",
        "print('Shape of Ca',categorical_vec.shape)\n",
        "categorical_vec[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0PAN-NvMIfv",
        "outputId": "05b84c56-b04d-40bb-d6f5-752a2da28fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Ca (143, 22)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=100\n",
        "embed_dim=300\n",
        "lstm_num=50\n",
        "output_dim=categorical_vec.shape[1]\n",
        "input_dim=len(unique_intents)\n",
        "print(\"Input Dimension :{},\\nOutput Dimension :{}\".format(input_dim,output_dim))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72LSaPuiMVN2",
        "outputId": "cb13fd09-c100-4053-d084-d585251de6c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Dimension :22,\n",
            "Output Dimension :22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\ttf.keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim),\n",
        "\ttf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_num, dropout=0.1)),\n",
        "\ttf.keras.layers.Dense(lstm_num, activation='relu'),\n",
        "\ttf.keras.layers.Dropout(0.4),\n",
        "\ttf.keras.layers.Dense(output_dim, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMFXYCSxMczB",
        "outputId": "0a7b7fd1-9234-4ac6-e3d4-a1f3d1041414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 300)         35700     \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 100)               140400    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 22)                1122      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 182272 (712.00 KB)\n",
            "Trainable params: 182272 (712.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(padded_sequences, categorical_vec, epochs=epochs, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "livuQJUGMjRh",
        "outputId": "b71f0706-ecc2-47ee-dd12-6520b3f66d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79890bf59b40>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text_inputs = [\"Hello\",\n",
        "\t\t\t\t\t\"my name is adam\",\n",
        "\t\t\t\t\t\"how are you?\",\n",
        "\t\t\t\t\t\"can you guess my name?\",\n",
        "\t\t\t\t\t\"Do you get me\",\"Adios\"]\n",
        "\n",
        "test_intents = [\"Greeting\",\n",
        "\t\t\t\t\"GreetingResponse\",\n",
        "\t\t\t\t\"CourtesyGreeting\",\n",
        "\t\t\t\t\"CurrentHumanQuery\",\n",
        "\t\t\t\t\"UnderstandQuery\",\n",
        "\t\t\t\t\"GoodBye\"]\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_text_inputs)\n",
        "test_padded_sequences = pad_sequences(test_sequences, padding='pre')\n",
        "test_labels = np.array([unique_intents.index(intent) for intent in test_intents])\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "loss, accuracy = model.evaluate(test_padded_sequences, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uBezdPqMrys",
        "outputId": "79daac20-8a05-49a7-8b45-d9faaa9c0c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 0.3190 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def response(sentence):\n",
        "\tsent_tokens = []\n",
        "\t# Split the input sentence into words\n",
        "\twords = sentence.split()\n",
        "\t# Convert words to their corresponding word indices\n",
        "\tfor word in words:\n",
        "\t\tif word in tokenizer.word_index:\n",
        "\t\t\tsent_tokens.append(tokenizer.word_index[word])\n",
        "\t\telse:\n",
        "\t\t\t# Handle unknown words\n",
        "\t\t\tsent_tokens.append(tokenizer.word_index['<unk>'])\n",
        "\tsent_tokens = tf.expand_dims(sent_tokens, 0)\n",
        "\t#predict numerical category\n",
        "\tpred = model(sent_tokens)\n",
        "\t#category to intent\n",
        "\tpred_class = np.argmax(pred.numpy(), axis=1)\n",
        "\t# random response to that intent\n",
        "\treturn random.choice(\n",
        "\t\tresponse_for_intent[index_to_intent[pred_class[0]]]), index_to_intent[pred_class[0]]\n"
      ],
      "metadata": {
        "id": "1TqtGYFBMx4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Note: Enter 'quit' to break the loop.\")\n",
        "while True:\n",
        "\tquery = input('You: ')\n",
        "\tif query.lower() == 'quit':\n",
        "\t\tbreak\n",
        "\tbot_response, typ = response(query)\n",
        "\tprint('Geek: {} -- TYPE: {}'.format(bot_response, typ))\n",
        "\tprint()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjNBIfEvM2-V",
        "outputId": "9be0663a-120e-44ab-f454-465f8c94fd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: Enter 'quit' to break the loop.\n",
            "You: quit\n"
          ]
        }
      ]
    }
  ]
}